apiVersion: apps.ops.dev/v1alpha1
kind: PodSleuth
metadata:
  name: podsleuth-test
spec:
  # Reconcile interval (optional, default: 5 minutes)
  reconcileInterval: 5m
  
  # Pod label selector to filter test pods
  # This will monitor all pods with environment=test label across all namespaces
  podLabelSelector:
    matchLabels:
      environment: test
    # You can also use matchExpressions for more complex filtering:
    # matchExpressions:
    #   - key: environment
    #     operator: In
    #     values:
    #     - test
    #     - staging
  
  # Log analysis configuration for test environment
  # Configured to detect Kafka connection errors from test5 (app5-deployment)
  # and Redis connection errors from test6 (app6-deployment)
  # NEW STRUCTURE: Using methodConfigs for better separation of concerns
  logAnalysis:
    enabled: true

    # Cache configuration - prevents re-analyzing same logs on every reconcile
    cacheEnabled: true
    cacheTTL: 5m  # Cache results for 5 minutes

    # Log retrieval configuration
    linesToAnalyze: 200
    filterErrorsOnly: true

    # Method-specific configurations (NEW RECOMMENDED WAY)
    # Methods are executed in the order specified: pattern first (fast), then AI (comprehensive)
    methodConfigs:
      # Pattern analysis method - Fast keyword-based detection
      - type: "pattern"
        patternConfig:
          patterns:
            - name: "KafkaConnectionError"
              pattern: "(?i)(broker not available|leader not available|connection to node|kafka.*connection.*failed|kafka.*service.*down|kafka.*service.*unreachable)"
              rootCause: "Kafka service is down or unreachable"
              priority: 15
            - name: "RedisConnectionError"
              pattern: "(?i)(redis.*connection.*refused|redis.*timeout|cannot connect to redis)"
              rootCause: "Redis service is down or unreachable"
              priority: 12

      # AI analysis method - Comprehensive AI-powered analysis using Ollama
      - type: "ai"
        aiConfig:
          endpoint: "http://localhost:11434/api/generate"
          format: "ollama"
          model: "qwen3:8b"  # Using qwen3:8b model (make sure it's installed in Ollama)
          # Ollama typically doesn't require authentication
          # Optional: Uncomment if your AI service requires authentication
          # apiKeySecretRef:
          #   name: "ollama-api-key-secret"
          #   key: "api-key"
          # authHeader: "Authorization"
          # authPrefix: "Bearer"
